{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, split, explode, count, col\n",
    "from pyspark.sql.types import List, StringType\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"adj\").getOrCreate()\n",
    "path = \"../../simulated_postgres/filtered_DE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# der postgres driver muss so verknüpft werden:\n",
    "# spark-submit --jars pfad/postgresql-42.7.2.jar basics.ipynb\n",
    "# das geht in notebooks nicht. als .py funktioniert es\n",
    "\n",
    "\n",
    "# env = {\n",
    "#     \"user\": \"bigdata\",\n",
    "#     \"password\": \"bigdata\",\n",
    "#     \"driver\": \"org.postgresql.Driver\",\n",
    "# }\n",
    "\n",
    "# DB_url = \"jdbc:postgresql://localhost:5432/mydatabase\"\n",
    "\n",
    "# # Read DataFrame from PostgreSQL\n",
    "# df = spark.read \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", DB_url) \\\n",
    "#     .option(\"dbtable\", \"filtered_de\") \\  # Specify the table name\n",
    "#     .option(\"user\", env[\"user\"]) \\\n",
    "#     .option(\"password\", env[\"password\"]) \\\n",
    "#     .option(\"driver\", env[\"driver\"]) \\\n",
    "#     .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",'True').option('delimiter', ',').csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "|   video_id|               title|         publishedAt|           channelId|        channelTitle|categoryId|trending_date|                tags|view_count|comment_count|comments_disabled|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "|jhMP8RSv4ws|Final-Auftritt vo...|2024-02-17T21:40:00Z|UCvbR8mrSZ1BXf2LN...|     Das Supertalent|        24|     24.18.02|Supertalent|Das S...|    514610|          336|            False|\n",
      "|xeLMS48vrZU|Anna Ermakova - '...|2024-02-17T21:50:00Z|UCvbR8mrSZ1BXf2LN...|     Das Supertalent|        24|     24.18.02|Supertalent|Das S...|    487691|          332|            False|\n",
      "|CxpUiuI9O4s|Der unfassbare Fa...|2024-02-18T11:00:08Z|UCKGMHVipEvuZudhH...|      Simplicissimus|        24|     24.18.02|Simplicissimus|2 ...|    191084|          607|            False|\n",
      "|-ppK-fWTlPA|6 MÄDELS BLIND DA...|2024-02-18T11:00:00Z|UCOnQ-e7kr4zKwR6R...|               CEDDO|        24|     24.18.02|ceddotalk|ceddo|b...|     78050|           95|            False|\n",
      "|nnOBbfVPRa8|Ich habe versucht...|2024-02-17T17:15:01Z|UC8E8eD7mOcnMazJT...|                Domo|        24|     24.18.02|Papaplatte|papapl...|    371820|          260|            False|\n",
      "|K9W12m6YGdE|Meine NERVEN LIEG...|2024-02-18T09:03:25Z|UCY7aQw00ds31nu29...|              Broski|        24|     24.18.02|gamerbrother|game...|    117771|          208|            False|\n",
      "|y95-aTC3HSU|Also wenn Skull a...|2024-02-17T16:00:28Z|UC6C1dyHHOMVIBAze...|            GameStar|        20|     24.18.02|spiele|game|gamep...|    447724|         2549|            False|\n",
      "|tKbObjo_68A|The FULL 2024 NBA...|2024-02-18T04:11:04Z|UCWJ2lWNubArHWmf3...|                 NBA|        17|     24.18.02|Basketball|G Leag...|   2336921|         4702|            False|\n",
      "|YhgCX2gTf7w|  ALMAN in der SAUNA|2024-02-18T10:00:17Z|UCwCpW0IbR0Z2WJry...|          Phil Laude|        24|     24.18.02|Alman|Alman vs Br...|    109911|          168|            False|\n",
      "|Onrjy0iGsPU|DIESES KREISLIGA ...|2024-02-18T11:00:29Z|UCgmHVWU9vo_Y4fiQ...|            Brotatos|        24|     24.18.02|fußball|challenge...|    161582|         1395|            False|\n",
      "|bFP9H0U1814|Die Aufrechten: D...|2024-02-17T07:00:14Z|UC1w6pNGiiLdZgyNp...|         DER SPIEGEL|        25|     24.18.02|Reportage|News|Po...|    585838|         3975|            False|\n",
      "|s3Vsvd9cuFQ|Isaak - Always On...|2024-02-17T00:05:55Z|UC238kiEEktbDUpIR...|Eurovision Song C...|        24|     24.18.02|Always On The Run...|    575468|         2141|            False|\n",
      "|AoLpWZPQuQ0|Isaak - Always On...|2024-02-16T22:06:53Z|UC238kiEEktbDUpIR...|Eurovision Song C...|        24|     24.18.02|Always On The Run...|    491572|         2532|            False|\n",
      "|-eqXQDLLEhc|Nur ein toter Bug...|2024-02-18T08:00:00Z|UC6C1dyHHOMVIBAze...|            GameStar|        20|     24.18.02|spiele|game|gamep...|    147093|          460|            False|\n",
      "|W0iQguIT_yE|MASSIVE ANNOUNCEM...|2024-02-17T17:13:43Z|UC4-79UOlP48-QNGg...|           MrBeast 2|        22|     24.18.02|              [none]|   3390103|        10505|            False|\n",
      "|-9a7awgvfuo|Worauf habt ihr g...|2024-02-16T17:00:07Z|UCpKgxZ4SgMKAgvQF...|           itsAssiTV|        20|     24.18.02|ps4|deutsch|Freun...|    263543|         2319|            False|\n",
      "|xQc5ea-cZrI|Unfassbar schlech...|2024-02-18T09:14:58Z|UCYAg4bYdyqENxEyH...|            der8auer|        28|     24.18.02|              [none]|     53240|          414|            False|\n",
      "|wujxPjysuAQ|Der unfairste Spe...|2024-02-18T11:15:02Z|UCMXLdjrQi4JzY0NN...|                Ulti|        20|     24.18.02|Yu-Gi-Oh!|Forbidd...|     65298|          214|            False|\n",
      "|whAvQZAili8|Patrick Cercel si...|2024-02-18T12:00:09Z|UCKQ3aENaIBeDGNz2...|Ionut Cercel © Of...|        10|     24.18.02|              [none]|    221252|         1119|            False|\n",
      "|k9nalORue4A|      Das Dorfleben.|2024-02-18T09:00:27Z|UCw81xLtFkpks4D8_...|              Varion|        23|     24.18.02|varion|fun|scetch...|     79555|          171|            False|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "(1000, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.show()\n",
    "# df.dropDuplicates(['video_id']).show()\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "/var/folders/cn/t7fpnv554854x0vj7r6fxyjh0000gn/T/ipykernel_28633/2080672334.py:1: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  df = df.withColumn(\"tags\",split(\"tags\", \"\\|\") )\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"tags\",split(\"tags\", \"\\|\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "|   video_id|               title|         publishedAt|           channelId|        channelTitle|categoryId|trending_date|                tags|view_count|comment_count|comments_disabled|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "|jhMP8RSv4ws|Final-Auftritt vo...|2024-02-17T21:40:00Z|UCvbR8mrSZ1BXf2LN...|     Das Supertalent|        24|     24.18.02|[Supertalent, Das...|    514610|          336|            False|\n",
      "|xeLMS48vrZU|Anna Ermakova - '...|2024-02-17T21:50:00Z|UCvbR8mrSZ1BXf2LN...|     Das Supertalent|        24|     24.18.02|[Supertalent, Das...|    487691|          332|            False|\n",
      "|CxpUiuI9O4s|Der unfassbare Fa...|2024-02-18T11:00:08Z|UCKGMHVipEvuZudhH...|      Simplicissimus|        24|     24.18.02|[Simplicissimus, ...|    191084|          607|            False|\n",
      "|-ppK-fWTlPA|6 MÄDELS BLIND DA...|2024-02-18T11:00:00Z|UCOnQ-e7kr4zKwR6R...|               CEDDO|        24|     24.18.02|[ceddotalk, ceddo...|     78050|           95|            False|\n",
      "|nnOBbfVPRa8|Ich habe versucht...|2024-02-17T17:15:01Z|UC8E8eD7mOcnMazJT...|                Domo|        24|     24.18.02|[Papaplatte, papa...|    371820|          260|            False|\n",
      "|K9W12m6YGdE|Meine NERVEN LIEG...|2024-02-18T09:03:25Z|UCY7aQw00ds31nu29...|              Broski|        24|     24.18.02|[gamerbrother, ga...|    117771|          208|            False|\n",
      "|y95-aTC3HSU|Also wenn Skull a...|2024-02-17T16:00:28Z|UC6C1dyHHOMVIBAze...|            GameStar|        20|     24.18.02|[spiele, game, ga...|    447724|         2549|            False|\n",
      "|tKbObjo_68A|The FULL 2024 NBA...|2024-02-18T04:11:04Z|UCWJ2lWNubArHWmf3...|                 NBA|        17|     24.18.02|[Basketball, G Le...|   2336921|         4702|            False|\n",
      "|YhgCX2gTf7w|  ALMAN in der SAUNA|2024-02-18T10:00:17Z|UCwCpW0IbR0Z2WJry...|          Phil Laude|        24|     24.18.02|[Alman, Alman vs ...|    109911|          168|            False|\n",
      "|Onrjy0iGsPU|DIESES KREISLIGA ...|2024-02-18T11:00:29Z|UCgmHVWU9vo_Y4fiQ...|            Brotatos|        24|     24.18.02|[fußball, challen...|    161582|         1395|            False|\n",
      "|bFP9H0U1814|Die Aufrechten: D...|2024-02-17T07:00:14Z|UC1w6pNGiiLdZgyNp...|         DER SPIEGEL|        25|     24.18.02|[Reportage, News,...|    585838|         3975|            False|\n",
      "|s3Vsvd9cuFQ|Isaak - Always On...|2024-02-17T00:05:55Z|UC238kiEEktbDUpIR...|Eurovision Song C...|        24|     24.18.02|[Always On The Ru...|    575468|         2141|            False|\n",
      "|AoLpWZPQuQ0|Isaak - Always On...|2024-02-16T22:06:53Z|UC238kiEEktbDUpIR...|Eurovision Song C...|        24|     24.18.02|[Always On The Ru...|    491572|         2532|            False|\n",
      "|-eqXQDLLEhc|Nur ein toter Bug...|2024-02-18T08:00:00Z|UC6C1dyHHOMVIBAze...|            GameStar|        20|     24.18.02|[spiele, game, ga...|    147093|          460|            False|\n",
      "|W0iQguIT_yE|MASSIVE ANNOUNCEM...|2024-02-17T17:13:43Z|UC4-79UOlP48-QNGg...|           MrBeast 2|        22|     24.18.02|            [[none]]|   3390103|        10505|            False|\n",
      "|-9a7awgvfuo|Worauf habt ihr g...|2024-02-16T17:00:07Z|UCpKgxZ4SgMKAgvQF...|           itsAssiTV|        20|     24.18.02|[ps4, deutsch, Fr...|    263543|         2319|            False|\n",
      "|xQc5ea-cZrI|Unfassbar schlech...|2024-02-18T09:14:58Z|UCYAg4bYdyqENxEyH...|            der8auer|        28|     24.18.02|            [[none]]|     53240|          414|            False|\n",
      "|wujxPjysuAQ|Der unfairste Spe...|2024-02-18T11:15:02Z|UCMXLdjrQi4JzY0NN...|                Ulti|        20|     24.18.02|[Yu-Gi-Oh!, Forbi...|     65298|          214|            False|\n",
      "|whAvQZAili8|Patrick Cercel si...|2024-02-18T12:00:09Z|UCKQ3aENaIBeDGNz2...|Ionut Cercel © Of...|        10|     24.18.02|            [[none]]|    221252|         1119|            False|\n",
      "|k9nalORue4A|      Das Dorfleben.|2024-02-18T09:00:27Z|UCw81xLtFkpks4D8_...|              Varion|        23|     24.18.02|[varion, fun, sce...|     79555|          171|            False|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+----------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videosAsListOfTags = df.select(\"tags\").rdd.flatMap(lambda x: x).collect()\n",
    "len(videosAsListOfTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|   video_id|                tags|\n",
      "+-----------+--------------------+\n",
      "|jhMP8RSv4ws|         Supertalent|\n",
      "|jhMP8RSv4ws|     Das Supertalent|\n",
      "|jhMP8RSv4ws|         Deutschland|\n",
      "|jhMP8RSv4ws|                 RTL|\n",
      "|jhMP8RSv4ws|       Bruce Darnell|\n",
      "|jhMP8RSv4ws|       Dieter Bohlen|\n",
      "|jhMP8RSv4ws|        Super Talent|\n",
      "|jhMP8RSv4ws|     Daniel Hartwich|\n",
      "|jhMP8RSv4ws|                  TV|\n",
      "|jhMP8RSv4ws|          Television|\n",
      "|jhMP8RSv4ws|           Fernsehen|\n",
      "|jhMP8RSv4ws|             Casting|\n",
      "|jhMP8RSv4ws|      Modern Talking|\n",
      "|jhMP8RSv4ws|Germany's Got Talent|\n",
      "|jhMP8RSv4ws|          Got Talent|\n",
      "|jhMP8RSv4ws|             Germany|\n",
      "|jhMP8RSv4ws|              Talent|\n",
      "|jhMP8RSv4ws|        Lola Weipert|\n",
      "|jhMP8RSv4ws|    Ehrlich Brothers|\n",
      "|jhMP8RSv4ws|  Riccardo Simonetti|\n",
      "+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_tags = df.select(\"video_id\", explode(\"tags\").alias(\"tags\"))\n",
    "all_tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_tags = all_tags.groupBy(\"tags\").agg(count(\"tags\").alias(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_tags = counted_tags.orderBy(\"count\", ascending=False).limit(500)\n",
    "topxtags = dict(counted_tags.rdd.map(lambda row: (row[\"tags\"], row[\"count\"])).collect())\n",
    "tagToID = {k: i for i, (k, _) in enumerate(topxtags.items())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| tags_pair|count|\n",
      "+----------+-----+\n",
      "|{176, 220}|   10|\n",
      "|  {176, 5}|   10|\n",
      "| {176, 14}|   10|\n",
      "|{176, 185}|   10|\n",
      "|{176, 218}|   10|\n",
      "|{176, 233}|   10|\n",
      "|{176, 182}|   10|\n",
      "| {176, 73}|   10|\n",
      "|{176, 225}|   10|\n",
      "|{176, 131}|   10|\n",
      "|{176, 136}|   10|\n",
      "|{176, 179}|   10|\n",
      "|{176, 212}|   10|\n",
      "|{176, 237}|   10|\n",
      "| {176, 60}|   10|\n",
      "|{176, 210}|   10|\n",
      "|{176, 177}|   10|\n",
      "|{176, 175}|   10|\n",
      "|{176, 216}|   10|\n",
      "|{176, 236}|   10|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adj_mat = (df.select(\"tags\")\n",
    "           .rdd # convert to rdd\n",
    "           .flatMap(lambda row: combinations(row[\"tags\"], 2)) # finds all combinations\n",
    "           .filter(lambda tags: all(tagToID.get(tag) is not None for tag in tags)) # remove all combinations not in top500\n",
    "           .map(lambda tags: ((tagToID[tags[0]], tagToID[tags[1]]), 1)) #set count 1 and use touple\n",
    "           .reduceByKey(lambda x, y: x + y) # all all cvalid combinatiosn together\n",
    "           .toDF([\"tags_pair\", \"count\"])) #return to df\n",
    "adj_mat.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+\n",
      "|count|tag1|tag2|\n",
      "+-----+----+----+\n",
      "|   10| 176| 220|\n",
      "|   10| 176|   5|\n",
      "|   10| 176|  14|\n",
      "|   10| 176| 185|\n",
      "|   10| 176| 218|\n",
      "|   10| 176| 233|\n",
      "|   10| 176| 182|\n",
      "|   10| 176|  73|\n",
      "|   10| 176| 225|\n",
      "|   10| 176| 131|\n",
      "|   10| 176| 136|\n",
      "|   10| 176| 179|\n",
      "|   10| 176| 212|\n",
      "|   10| 176| 237|\n",
      "|   10| 176|  60|\n",
      "|   10| 176| 210|\n",
      "|   10| 176| 177|\n",
      "|   10| 176| 175|\n",
      "|   10| 176| 216|\n",
      "|   10| 176| 236|\n",
      "+-----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edge_table = adj_mat.withColumn(\"tag1\", col(\"tags_pair\").getItem(\"_1\")) \\\n",
    "             .withColumn(\"tag2\", col(\"tags_pair\").getItem(\"_2\")) \\\n",
    "             .drop(\"tags_pair\")\n",
    "edge_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|weight|              source|         destination|\n",
      "+------+--------------------+--------------------+\n",
      "|    32|            Fussball|                 DFB|\n",
      "|    29|             Fußball|                 DFB|\n",
      "|    25|                 RTL|      Lukas Podolski|\n",
      "|    25|                 RTL|                RTL+|\n",
      "|    25|                 RTL|               RTL +|\n",
      "|    25|                 RTL|            RTL Plus|\n",
      "|    25|                RTL+|               RTL +|\n",
      "|    25|                RTL+|            RTL Plus|\n",
      "|    24|              Soccer|                 DFB|\n",
      "|    24|            Football|                 DFB|\n",
      "|    22|            Fussball|         Deutschland|\n",
      "|    22|             Fußball|          Bundesliga|\n",
      "|    20|papaplatte highli...|papaplatte best o...|\n",
      "|    20|papaplatte highli...| papaplatte realtalk|\n",
      "|    20|papaplatte best o...| papaplatte realtalk|\n",
      "|    20|            Fussball|              Soccer|\n",
      "|    20|            Fussball|            Football|\n",
      "|    20|             Fußball|          Highlights|\n",
      "|    20|              Soccer|         Deutschland|\n",
      "|    20|            Football|         Deutschland|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "IDtoTag = {v: k for k, v in tagToID.items()}\n",
    "\n",
    "def replace_id_with_name(id_value):\n",
    "    return IDtoTag.get(id_value, id_value)\n",
    "\n",
    "replace_id_with_name_udf = udf(replace_id_with_name, StringType())\n",
    "\n",
    "\n",
    "new_edge = edge_table.withColumn(\"tag1\", replace_id_with_name_udf(col(\"tag1\")))\n",
    "new_edge = new_edge.withColumn(\"tag2\", replace_id_with_name_udf(col(\"tag2\")))\n",
    "\n",
    "new_edge = new_edge.withColumnRenamed('count', 'weight') \\\n",
    "      .withColumnRenamed('tag1', 'source') \\\n",
    "      .withColumnRenamed('tag2', 'destination')\n",
    "\n",
    "new_edge = new_edge.orderBy(\"weight\", ascending=False).limit(500)\n",
    "\n",
    "new_edge.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge.toPandas().to_csv('../../simulated_postgres/edge_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o229.save.\n: java.lang.ClassNotFoundException: org.postgresql.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 22\u001b[0m\n\u001b[1;32m     11\u001b[0m DB_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjdbc:postgresql://localhost:5432/mydatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Write DataFrame to PostgreSQL\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDB_url\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medge_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/sql/readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o229.save.\n: java.lang.ClassNotFoundException: org.postgresql.Driver\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:588)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n\tat org.apache.spark.sql.execution.datasources.jdbc.DriverRegistry$.register(DriverRegistry.scala:46)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$1$adapted(JDBCOptions.scala:103)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:103)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:250)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n"
     ]
    }
   ],
   "source": [
    "# Fiktiver Upload to PostgresSQL\n",
    "\n",
    "# der postgres driver muss so verknüpft werden:\n",
    "# spark-submit --jars pfad/postgresql-42.7.2.jar basics.ipynb\n",
    "# das geht in notebooks nicht. als .py funktioniert es\n",
    "\n",
    "\n",
    "env = {\n",
    "    \"user\": \"bigdata\",\n",
    "    \"password\": \"bigdata\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "\n",
    "\n",
    "DB_url = \"jdbc:postgresql://localhost:5432/mydatabase\"\n",
    "\n",
    "# Write DataFrame to PostgreSQL\n",
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", DB_url) \\\n",
    "    .option(\"dbtable\", \"edge_table\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"user\", env[\"user\"]) \\\n",
    "    .option(\"password\", env[\"password\"]) \\\n",
    "    .option(\"driver\", env[\"driver\"]) \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
